+++
title = "Recording and Mix Philiosophies"
description = "Reflecting on positions I've held regarding professional sound work"
draft = true
weight = 80
[taxonomies]
tags = ["Audio"]
[extra]
featured = false
banner = ""
hero = false
+++

<!---


## No. 1 - 'Fix it in the mix' mentality should be avoided as far as realistically possible..
This kind of mentality requires more processing come mix stage which in turn can have serious repercussions on sound quality. Equalisation introduces various 'ripple' effects as a byproduct of processing because they usually operate through adding/subtracting multiple delayed copies of the source at various volumes. As a filter works by combining these delays with the original signal, its pretty easy to see that upon output the source could be unintentionally reshaped or distorted in both frequency and phase (time).

For instance high pass filtering to instruments such as the bass guitar could be thought of as quite destructive because the amount of delay required to cancel a low frequency is proportional to the wavelength. When high pass filtering we essentially introduce the most noticeable delays first; so cutting a lot of low end from a track will essentially smear the remaining high frequencies in similar proportions! 

Its also worth noting that inter-aural timing differences are used to localise low frequencies; despite this aspect only being in regard to the localisation of a sound–and low frequency primarily being placed in the center (mono)–introducing such phase distortions in the low end should be carefully considered or ideally accounted for at the recording stage. 

Regardless of these points we have to accept that nobody has infinite time to capture the 'perfect sound' and so compromises must always be made; respectively I feel that when they are made its an engineers responsibility to know how to minimise them to the smallest possible degree.


## No. 2 - Compressors can output nasty and nice distortions; pick and choose with automation...
Setting the attack and release time of a compressor is a great way of changing somethings timbre; I suppose this should come as no surprise given that their main byproduct is harmonic distortion. Harmonic distortion needn't be thought of a bad thing as it is often considered, but more like a form of coloration which is why some units are so sought after. Just form the name it seems clear that the harmonic distortion of our equipment will have musical implications which could be either be good (colouration/'glue') or bad (slammed too hard introducing too many overtones and other artifacts).

Aside from harmonic distortion there is the topic of intermodulation distortion (IMD) which occurs as frequencies interact with each other creating additional components at their sum and difference. Given that our tuning systems are derived from a similar process (dividing octaves to create scale steps) and the quite simple math of harmonically related material we can see how IMD could sometimes be musical:

The notes A and E are a musical 5th apart; they are at 55hz and 82hz respectively. The sum [55+82 = 137] which is practically a C# (at 138hz). This is a major 3rd in the key of A our root which makes an A major chord. Technically the difference of 1hz is virtually undetectable and our brains will still categorise 137hz as a C# in the broader scheme of things. Having a small amount of this distortion is perfectly acceptable and results in a subtle colouration; its when larger amounts of distortion are present that it becomes problematic as distantly related frequencies start to pile up and obscure the source. This might not necessarily mean anything in the overall picture of how music is perceived–especially when dealing with a complex signal–however it serves to illustrate the point that when something sounds good we should not fear to call it 'musical' because it just may be! See <a href="http://www.aes.org/e-lib/browse.cfm?elib=784">here</a> for further reading.

Another byproduct of compression is the effect it has on a transients rate of motion, which as a colleague pointed out to me can be used to our advantage. Think of a transient getting compressed and then brought back up to the pre-compressed level, as the zero crossing point (minimum volume) is still at the same level, the speed at which a waveform reaches its peak is increased post-compression and can thereby be thought of as increasing 'snap' or the perceived tightness of the musicians being increased due to the reduction of micro timing differences.

Compression, however useful, can be dangerous when incorrectly applied and can easily kill a tracks natural dynamic. To get around this problem I generally write automation that levels the wave form of drastic peaks and level changes between sections, bounce and process with compression for its tonal purposes after which re-automating the macro dynamics back to their intended volumes. Many times a musician plays quietly for a tonal dynamic and so these passages can require a lot of automation, the results though are nearly always a hundred times better than if a track had to be squashed in order to accommodate such level differences. A practice of hard compressing is counter productive to a musicians intended feel; as the track gets louder it looses strength against the compression resulting in a loss of impact and gaining definition as it becomes quieter...

### No. 3 - Masking calls for compromise...
Psychoacoustics tells us that low frequencies mask higher ones and that an excessive boost at one frequency band will cause a lack of audibility in another due to critical bands in the ear. For instance if bass frequencies are over emphasised we can simply loose definition/audibility in the midrange as its masked (this is quite important as the most receptive part of our hearing is the midrange). On a recorded signal like this there are then two choices; leave in unnecessary low end that can build up and mask the midrange or take it out with equalisation which will cause a phase ripple/time smear. Eventually it comes down to whats subjectively more destructive and although my vote goes to masking I feel that a balance between the two is optimal; theres no need to filter every channel, but an amount of equalisation is always going to be necessary to complete a mix.

### No. 4 - Get on well; get a good performance...
This almost goes without saying but it really is a fact of life; music can be quite a personal thing and as such even a performer used to playing to a large crowd can be uncomfortable playing behind the glass; especially with someone they don't like. For musicians an analogy could be drawn to sitting down with a stranger and playing to them for some time; if you get along well and have fun playing for hours is no problem, while if you get the impression their not interested in the slightest how long are you going to stay engaged?

Finding compositional aspects of the music that you enjoy and offering genuine positive feedback is a great way to get on with artists in the studio; everyone likes to be told their musics good, while meaning every word of what you say will also gain a lot of trust. One thing I have found to be advantageous in this respect is having a musical background; conveying thoughts is relatively easy with musicians who understand theory but even for those that don't the ability to sing a melody or guitar line accurately enough is useful for communication purposes and can really facilitate a good rapport with the musicians.
<h2>No.5 - Good gear helps but there is no such thing as magic...</h2>

If you record through dodgy converters the mix is going to be an uphill battle; however running through a Neve will not automatically make things sound great (despite the probably well deserved hype). The same can be said about plug-ins; just because it cost £800 for the bundle (or <a href="http://www.waves.com/content.aspx?id=90">much much more</a>) does not mean that processing every track will make for a great mix and will in all actuality probably destroy it. When it comes to gear I'm like every engineer and would like the best available, but in reality there are budget constraints and rather than complain about this I would rather get on with the job and piece together the best quality signal chain possible at the time. A well placed microphone will sound a hundred times better than something thrown up and then run through a really nice signal chain...

Actually I lied; there is such a thing as magic...
Its the music... a good composition, played well by a decent musician can survive <a href="http://www.youtube.com/watch?v=PFtOpIHByNs">anything</a>.

--->