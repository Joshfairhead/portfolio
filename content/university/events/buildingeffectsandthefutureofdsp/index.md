
# London College of Music Masterclass - Building Effects and the Future of DSP

Took place on the Tuesday 4th May at 18:30 in TC102, University of West London and was presented by Josh Reiss of Queen Marys.

This was a talk organised by myself and a peer as we grew interested in DSP. After discussing the possibility of a master class with our course leader he suggested getting a friend of his called Josh Reiss in who is the head of Audio Engineering at the Centre for Digital Music at Queen Mary’s University of London and also a very active member of the AES.

Given his experience with companies such as SSL and Yamaha we asked him to give a presentation on the fundamentals of effect design followed by some slightly more advanced DSP theory and then to discuss the future of intelligent effects (as he is a pioneer in ‘auto-mixing’.

The presentation was excellent, explaining the fundamentals in an extremely coherent manner and included some of the best diagrams that I’ve seen to explainin digital filters. The final section of the talk was incredibly interesting as it was based around the future of intelligent effects units, here he discussed various pieces of software that he had been working on which used artificial intelligence to achieve various results. 

One of my favorite tools was a phase correction system where by the incoming audio signals are analysed and then time aligned for minimum phase cancellation; essentially automating a tedious manual process that I undertake before starting mix on most sessions. My course leader Justin Patterson had actually created a similar patch for the same task but had never shopped the idea commercially as he presented it publicly for the ARP conference; however Josh has been working with SSL to make this a reality… Credit to them both, but I'm really glad that this will be rolled out soon!

Other topics covered were automatic mixing devices that could for example find good compression settings and adapt them in real time dependent on the source. Although there is no substitute for the human ear, this is a system that I believe would be great with user defined limits... Imagine setting your compressors and then telling the computer that it can adapt the settings by a given amount; the user defines the macro and the machine works within these parameters on a micro scale optimising the settings dependent on the input. I think this has the potential to end up with really musical results provided the algorithm work well… 

To conclude I believe we have an interesting future in the field of audio technology/DSP and will be very much be looking forward to the further advances in the field; especially as certain plugin manufacturers at present have a growing tendency to dumb things down and remove user control... One knob trying to control everything? no thanks, thats a crippled system from the get go. User defined parameters optimised dependent on the signal source? YES PLEASE, THATS A GODSEND!
